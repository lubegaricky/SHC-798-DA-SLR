---
title: "SHC 798 Assignment 2, 2025"
author: "Richard Lubega"
date: "`r Sys.Date()`"
output:
  pdf_document:
    latex_engine: xelatex
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

# SHC 798 Assignment 2, 2025

## Multiple Linear Analysis (MLR)

### Question 1: Concrete Strength


```{r resplot, include=FALSE}
## Enhanced Function for Residual Plots
resplot <- function(obj, plots=1:4)
{
  ## Coded by: Marcel Dettling, September 18, 2015
  ## Argument: obj   - a regression fit, i.e. output of R-Function lm()
  ## Argument: plots - which plots to generate (1=Tukey-Anscombe, 2=Normal, 3=Scale-Location, 4=Leverage)
  
  ## Set number of frames in the plot
  if (length(plots)>=3) par(mfrow=c(2,2))
  if (length(plots)==2) par(mfrow=c(1,2))
  if (length(plots)==1) par(mfrow=c(1,1))
  
  ## Set random seed that plots look always the same
  set.seed(21)
  
  ## Tukey-Anscombe-Plot with Resampling
  if (1 %in% plots)
  {
    plot(fitted(obj), resid(obj), pch=20, xlab="Fitted Values", ylab="Residuals")
    title("Tukey-Anscombe-Plot with Resampling")
    for (i in 1:100) lines(loess.smooth(fitted(obj), sample(resid(obj, replace=TRUE))), col="grey")
    abline(h=0, lty=2)
    points(fitted(obj), resid(obj), pch=20); box()
    lines(loess.smooth(fitted(obj), resid(obj)), col="red")
  }
  
  ## Normal Plot with Resampling
  if (2 %in% plots)
  {
    qq <- qqnorm(rstandard(obj), pch=20, main="Normal Plot with Resampling", ylab="Standardized Residuals")
    for (i in 1:100) lines(sort(qq$x), sort(rnorm(length(qq$y), mean(qq$y), sd(qq$y))), col="grey")
    points(qq$x, qq$y, pch=20); box()
    qqline(rstandard(obj), lty=2)
  }
  
  ## Scale-Location-Plot with Resampling
  if (3 %in% plots)
  {
    plot(fitted(obj), sqrt(abs(rstandard(obj))), pch=20, ylab="sqrt(abs(Standardized Residuals))", xlab="Fitted Values", ylim=c(0, range(sqrt(abs(rstandard(obj))), na.rm=TRUE)[2]), main="Scale-Location with Resampling")
    for (i in 1:100) lines(loess.smooth(fitted(obj), sample(sqrt(abs(rstandard(obj))), replace=TRUE)), col="grey")
    points(fitted(obj), sqrt(abs(rstandard(obj))), pch=20); box()
    lines(loess.smooth(fitted(obj), sqrt(abs(rstandard(obj)))), col="red")
  }
  
  ## Leverage Plot (without Resampling, taken from plot.lm()
  if (4 %in% plots)
  {
    plot(obj, which=5, pch=20, caption="")
    title("Leverage Plot")
  }
}

```


```{r, Part-1-a}
pacman::p_load(tidymodels)

# Getting started with the dataset in concrete.csv
concrete <- read.csv(file.choose(), header = TRUE, na.strings = c("NA")) # open dataset
head(concrete) # View first few rows of the dataset
summary(concrete) # Get an overview of the dataset
str(concrete) # inspect the dataset and viewing column data types
# view(concrete)
unique(concrete$age)

# Part a): Data Preparation
# [a-1] Histograms with overlaid marginal density distributions
par(mfrow = c(2, 2))

# cement
hist(concrete$cement, main = "Histogram of Cement with Density", 
     xlab = "Cement", col = "lightblue", probability = TRUE, breaks = 15)
lines(density(concrete$cement), col = "red", lwd = 2)

# wcr
hist(concrete$wcr, main = "Histogram of WCR with Density", 
     xlab = "WCR", col = "lightgreen", probability = TRUE, breaks = 15)
lines(density(concrete$wcr), col = "red", lwd = 2)

# age
hist(concrete$age, main = "Histogram of Age with Density", 
     xlab = "Age", col = "lightcoral", probability = TRUE, breaks = 15)
lines(density(concrete$age), col = "red", lwd = 2)

# strength
hist(concrete$strength, main = "Histogram of Strength with Density", 
     xlab = "Strength", col = "purple", probability = TRUE, breaks = 15)
lines(density(concrete$strength), col = "red", lwd = 2)

par(mfrow = c(1, 1))

# [a-2] Scatter Plots of Strength against each Predictor
par(mfrow = c(2, 2))

# Strength vs Cement
plot(concrete$cement, concrete$strength, main = "Strength vs Cement", 
     xlab = "Cement", ylab = "Strength", pch = 16, col = "blue")


# Strength vs WCR
plot(concrete$wcr, concrete$strength, main = "Strength vs WCR", 
     xlab = "WCR", ylab = "Strength", pch = 16, col = "green")

# Strength vs Age
plot(concrete$age, concrete$strength, main = "Strength vs Age", 
     xlab = "Age", ylab = "Strength", pch = 16, col = "red")

par(mfrow = c(1, 1))


```

#### **Commenting on the Trend and Need for Variable Transformation**

The marginal plots are not skewed. No clear need for variable transformations

The scatter plot for strength vs age indicates has distinct values (7, 14, 28, 56) which suggests a discrete or categorical nature rather than continuous. The marginal plots also show spikes at these specific ages rather than a smooth distribution.

Therefore, age may be as a **categorical variable** (factor) in regression to account for its discrete levels. Including *interaction terms* (e.g., cement:age, wcr:age) in such a regression model may be also necessary.

```{r, Part-1-b}
# Part b): Multicollinearity among predictors

# (i) Pearson correlation coefficients
cor(concrete, method = "pearson")

# Compute the correlation matrix - Same!
cor_matrix <- cor(concrete[, c("cement","wcr","age","strength")])
print(cor_matrix)


# (ii) An ellipse plot to visualise collinearity
pacman::p_load(ellipse)
plotcorr(cor(concrete))


# (iii) Variance Inflation Factors (VIFs)
pacman::p_load(car)
conc_model <- lm(strength ~ cement + wcr + age, data = concrete)
vif(conc_model)

```

From the above **collinearity audit** checks (Pearson correlation coefficients and the ellipse plot), the somewhat elongated ellipses, particularly between cement and strength (0.46578632), and age and strength (0.6345642), suggest potential multicollinearity among these predictors.

This indicates that the predictors may be highly correlated with each other and with the response variable, but Since all VIF values are very close to 1 (well below 5), there is **no significant multicollinearity** among the predictors. This suggests that the predictors are largely independent of each other, which is ideal for a stable regression model.

```{r, Part-1-c}
# Part-C-1 Model
conc_model <- lm(strength ~ cement + wcr + age, data = concrete)
summary(conc_model)
confint(conc_model)

# Part C-2: Comment on the Model output
# -Regression coefficients
# -Model significance
# -Adequacy of fit, and
# -Appropriateness of fit

## Residual analysis
plot(conc_model, which=1)
resplot(conc_model, plots = 1)

plot(conc_model, which = 2)
resplot(conc_model, plots = 2)

## Scale-location plot
plot(conc_model, which = 3)
resplot(conc_model, plots = 3)

## Cook's Distance plot
plot(conc_model, which = 4)
plot(conc_model, which = 5)
resplot(conc_model, plots = 4)

# Autocorrelation using the Durbin-Watson test
pacman::p_load(lmtest)
dwtest(conc_model)

```

Assumptions not violated, No Autocorrelation.

```{r, Part-1-d}
# Part d): Variable Selection
# Backward Elimination with AIC
conc.back <- stats::step(conc_model, direction="backward")
summary(conc.back)
resplot(conc.back)

# Forward Selection with AIC
conc_null <- lm(strength ~ 1, data = concrete) # Intercept-only model
sc <- list(lower=conc_null, upper=conc_model)
conc.forw <- stats::step(conc_null, scope=sc, direction="forward", k=2)
summary(conc.forw)
resplot(conc.forw)


# AIC Stepwise Model Search: Both Directions Approach
# starting with the null model
conc.b1 <- stats::step(conc_null, scope = sc, direction = "both")
summary(conc.b1)
resplot(conc.b1)

# starting with the full model
conc.b2 <- stats::step(conc_model, scope = sc, direction = "both")
summary(conc.b2)
resplot(conc.b2)

# starting with a model somewhere in the middle
conc_mid <- lm(strength ~  wcr + age, data = concrete)
conc.b3 <- stats::step(conc_mid, scope = sc, direction = "both")
summary(conc.b3)
resplot(conc.b3)

# AIC is used when the principal aim is the prediction

```

All predictors are kept in all 6 models. There are no major improvements in residual plots for all the models. Also, no noticeable changes on predictor significance or model fit.


```{r, Part-1-e}
# Part e) 5-fold cross validation
# Full Model is (strength ~ cement + wcr + age)
# Reduced Model is (strength ~ cement + age); wcr is dropped to see effect on prediction performance

set.seed(123) # Set seed for reproducibility

n <- nrow(concrete) # Number of observations
k <- 5 # Number of folds
sb <- round(seq(0, n, length = (k + 1)))  # Fold boundaries

# Initialize vectors to store MSPE for each model
mspe_full <- numeric(k)
mspe_reduced <- numeric(k)

# 5-fold cross-validation for full model (strength ~ cement + wcr + age)
for (i in 1:k) {
  test <- (sb[k + 1 - i] + 1):sb[k + 2 - i]
  train <- (1:n)[-test]
  fit_full <- lm(strength ~ cement + wcr + age, data = concrete[train, ])
  pred_full <- predict(fit_full, newdata = concrete[test, ])
  mspe_full[i] <- mean((concrete$strength[test] - pred_full)^2, na.rm = TRUE)
}

# 5-fold cross-validation for reduced model (strength ~ cement + age)
for (i in 1:k) {
  test <- (sb[k + 1 - i] + 1):sb[k + 2 - i]  # Same fold split comparability
  train <- (1:n)[-test]
  fit_reduced <- lm(strength ~ cement + age, data = concrete[train, ])
  pred_reduced <- predict(fit_reduced, newdata = concrete[test, ])
  mspe_reduced[i] <- mean((concrete$strength[test] - pred_reduced)^2, na.rm = TRUE)
}

# Calculating overall MSPE for each model
mspe_full_mean <- mean(mspe_full, na.rm = TRUE)
mspe_reduced_mean <- mean(mspe_reduced, na.rm = TRUE)

# Report results
cat("MSPE per fold for Full Model:", mspe_full, "\n")
cat("MSPE per fold for Reduced Model:", mspe_reduced, "\n")
cat("MSPE for Full Model:", mspe_full_mean, "\n")
cat("MSPE for Reduced Model:", mspe_reduced_mean, "\n")

# Relative increase in MSPE
relative_increase <- ((mspe_reduced_mean - mspe_full_mean) / mspe_full_mean) * 100
cat("Relative increase in MSPE (%):", relative_increase, "\n")

# Box plots using MSPEs
# Combining MSPEs into a data frame for plotting
mspe_data <- data.frame(
  MSPE = c(mspe_full, mspe_reduced),
  Model = factor(rep(c("Full", "Reduced"), each = k))
)

# Generating box plots
boxplot(MSPE ~ Model, data = mspe_data, 
        main = "MSPE Comparison: Full vs Reduced Model",
        ylab = "Mean Squared Prediction Error (MPaÂ²)",
        col = c("lightblue", "lightgreen"),
        border = "black")

```

From the cross-validation exercise, The MSPE for the reduced is substantially higher (25.29973%) than the full model. Therefore, the variable wcr adds predictive power and the full model is preferable for prediction purposes.

```{r Part-1-f}
# Part f): Prediction
conc.str <- data.frame(cement=350, wcr=0.5, age=28)
# predict(conc_model, newdata = conc.str, interval = "conf")
predict(conc_model, newdata = conc.str, interval = "pred")

```



